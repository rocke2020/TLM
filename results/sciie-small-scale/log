2021-11-27 21:50:43,668 - INFO - __main__ - Sample 2619 of the training set: {'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'cls_labels': 0, 'input_ids': [101, 1996, 3818, 4118, 2003, 16330, 2006, 1031, 1031, 12553, 2951, 1033, 1033, 1010, 1026, 1026, 2966, 4871, 1028, 1028, 1998, 2192, 9530, 21163, 2015, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'special_tokens_mask': [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.
2021-11-27 21:50:43,668 - INFO - __main__ - Sample 456 of the training set: {'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'cls_labels': 3, 'input_ids': [101, 2256, 1031, 1031, 14676, 2291, 1033, 1033, 16024, 3375, 11746, 1998, 27059, 1026, 1026, 3674, 1998, 9089, 2098, 10266, 1028, 1028, 9675, 1999, 1037, 6251, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'special_tokens_mask': [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.
2021-11-27 21:50:43,668 - INFO - __main__ - Sample 102 of the training set: {'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'cls_labels': 0, 'input_ids': [101, 1996, 9233, 6412, 1997, 1037, 2678, 5537, 2083, 1037, 2309, 3746, 4949, 1998, 1037, 7444, 4367, 2038, 5097, 1999, 2195, 13100, 1010, 2164, 1031, 1031, 2678, 11347, 2075, 1998, 26384, 1033, 1033, 1010, 1026, 1026, 13379, 1028, 1028, 1010, 16061, 2075, 1010, 1998, 5107, 7680, 7849, 3989, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'special_tokens_mask': [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.
2021-11-27 21:50:47,188 - INFO - __main__ - preprocessing external datasets
2021-11-27 21:50:47,393 - INFO - __main__ - max_train_steps : 150000
2021-11-27 21:50:47,393 - INFO - __main__ - num_train_epochs : 1389
2021-11-27 21:50:48,617 - INFO - __main__ - ***** Running training *****
2021-11-27 21:50:48,618 - INFO - __main__ -   Num examples = 3219
2021-11-27 21:50:48,618 - INFO - __main__ -   Num Epochs = 1389
2021-11-27 21:50:48,618 - INFO - __main__ -   Instantaneous batch size per device = 30
2021-11-27 21:50:48,618 - INFO - __main__ -   Total train batch size (w. parallel, distributed & accumulation) = 30
2021-11-27 21:50:48,618 - INFO - __main__ -   Gradient Accumulation steps = 1
2021-11-27 21:50:48,618 - INFO - __main__ -   Total optimization steps = 150000
2021-11-27 21:51:57,348 - INFO - __main__ - step 100, learning rate 1.0000000000000002e-06, average loss 9.961444854736328
2021-11-27 21:53:11,416 - INFO - __main__ - step 200, learning rate 2.0000000000000003e-06, average loss 9.436182022094727
2021-11-27 21:54:25,366 - INFO - __main__ - step 300, learning rate 3e-06, average loss 9.014053344726562
2021-11-27 21:55:39,322 - INFO - __main__ - step 400, learning rate 4.000000000000001e-06, average loss 8.991739273071289
2021-11-27 21:56:53,255 - INFO - __main__ - step 500, learning rate 5e-06, average loss 8.485363006591797
2021-11-27 21:58:07,175 - INFO - __main__ - step 600, learning rate 6e-06, average loss 8.388847351074219
2021-11-27 21:59:21,127 - INFO - __main__ - step 700, learning rate 7.000000000000001e-06, average loss 7.950171947479248
2021-11-27 22:00:35,051 - INFO - __main__ - step 800, learning rate 8.000000000000001e-06, average loss 7.781019687652588
2021-11-27 22:01:48,987 - INFO - __main__ - step 900, learning rate 9e-06, average loss 7.551361083984375
2021-11-27 22:03:02,953 - INFO - __main__ - step 1000, learning rate 1e-05, average loss 7.690949440002441
2021-11-27 22:04:16,896 - INFO - __main__ - step 1100, learning rate 1.1000000000000001e-05, average loss 7.394055366516113
2021-11-27 22:05:30,840 - INFO - __main__ - step 1200, learning rate 1.2e-05, average loss 7.306619167327881
2021-11-27 22:06:44,793 - INFO - __main__ - step 1300, learning rate 1.3000000000000001e-05, average loss 7.547685146331787
2021-11-27 22:07:58,734 - INFO - __main__ - step 1400, learning rate 1.4000000000000001e-05, average loss 7.432821750640869
2021-11-27 22:09:12,675 - INFO - __main__ - step 1500, learning rate 1.5e-05, average loss 7.18135929107666
2021-11-27 22:10:26,630 - INFO - __main__ - step 1600, learning rate 1.6000000000000003e-05, average loss 6.981876373291016
2021-11-27 22:11:40,588 - INFO - __main__ - step 1700, learning rate 1.7000000000000003e-05, average loss 7.183238506317139
2021-11-27 22:12:54,536 - INFO - __main__ - step 1800, learning rate 1.8e-05, average loss 6.984765529632568
2021-11-27 22:14:08,464 - INFO - __main__ - step 1900, learning rate 1.9e-05, average loss 7.1397294998168945
2021-11-27 22:15:22,413 - INFO - __main__ - step 2000, learning rate 2e-05, average loss 6.9766526222229
2021-11-27 22:16:36,370 - INFO - __main__ - step 2100, learning rate 2.1e-05, average loss 6.832047939300537
2021-11-27 22:17:50,301 - INFO - __main__ - step 2200, learning rate 2.2000000000000003e-05, average loss 6.6152849197387695
2021-11-27 22:19:04,256 - INFO - __main__ - step 2300, learning rate 2.3000000000000003e-05, average loss 6.853947639465332
2021-11-27 22:20:18,207 - INFO - __main__ - step 2400, learning rate 2.4e-05, average loss 6.770755290985107
2021-11-27 22:21:32,162 - INFO - __main__ - step 2500, learning rate 2.5e-05, average loss 6.652717113494873
2021-11-27 22:22:46,133 - INFO - __main__ - step 2600, learning rate 2.6000000000000002e-05, average loss 6.855687141418457
2021-11-27 22:24:00,086 - INFO - __main__ - step 2700, learning rate 2.7000000000000002e-05, average loss 6.833905220031738
2021-11-27 22:25:14,037 - INFO - __main__ - step 2800, learning rate 2.8000000000000003e-05, average loss 6.895623683929443
2021-11-27 22:26:27,984 - INFO - __main__ - step 2900, learning rate 2.9e-05, average loss 6.426770210266113
